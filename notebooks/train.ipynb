{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using `cuda` device\n"
     ]
    }
   ],
   "source": [
    "from fern.model import Transformer\n",
    "from fern.config import FernConfig\n",
    "import torch\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from fern.tokenizer import BytePairEncoding\n",
    "\n",
    "torch.manual_seed(0)  # type: ignore\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using `{device}` device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Here we load a simple dataset (to be released) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fern.tokenizer.BytePairEncoding at 0x7f1f9415be50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe = BytePairEncoding.load(\"checkpoints/tokenizers/tes2304.tok\")\n",
    "bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: torch.Tensor = torch.load(\"data/books_concat_special.pt\")\n",
    "data = data.to(torch.int64).cuda()\n",
    "n = int(0.8 * len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the config and important constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "max_iters = 10000\n",
    "batch_size = 32\n",
    "eval_iters = 100\n",
    "eval_interval = 1000\n",
    "\n",
    "fern_config = FernConfig(\n",
    "    d_model=128,  #384\n",
    "    n_heads=8,\n",
    "    n_layers=32,\n",
    "    vocab_size=bpe.vocab_size,\n",
    "    block_size=512,  # 256\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "def get_batch(split: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - fern_config.block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + fern_config.block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + fern_config.block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()  # type: ignore\n",
    "def estimate_loss(m: torch.nn.Module) -> dict[str, torch.Tensor]:\n",
    "    out: dict[str, torch.Tensor] = {}\n",
    "    m.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.empty(eval_iters)\n",
    "        for i in tqdm_notebook(range(eval_iters)):\n",
    "            bX, bY = get_batch(split)\n",
    "            _logits, loss = m(bX, bY)\n",
    "            losses[i] = loss\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 9.0m\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(config=fern_config).to(device)\n",
    "def param_count(m: torch.nn.Module) -> str:\n",
    "    total_params = sum(torch.numel(param) for param in m.parameters(True))\n",
    "    suffixes = [\"\", \"k\", \"m\", \"b\", \"t\"]\n",
    "    i = 0\n",
    "    while total_params // 1000 != 0:\n",
    "        total_params /= 1000\n",
    "        i += 1\n",
    "    return f\"{total_params:.1f}{suffixes[i]}\"\n",
    "    \n",
    "print(f\"Model parameters: {param_count(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35af22b3ac944efae1fbedabf0daf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0241c69d4743427c9bbb5f26a18572ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d77ec50446e4f89a05d86771d3fc381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 0: {'train': tensor(8.3886), 'val': tensor(8.3873)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4f318f81da4155a59d3b166456b21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b2dcf4677749e4814ee7f9816844d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 1000: {'train': tensor(4.2836), 'val': tensor(4.3916)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af3b6f6d1394de09ffe158511d21a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0a9f7041bd4a8b9b2e3d45c816864e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 2000: {'train': tensor(3.7055), 'val': tensor(3.9195)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0216f175435d4194b6be32bf5d0cf1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594ec65adc9a4818833502eb27f8aaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 3000: {'train': tensor(3.4469), 'val': tensor(3.7515)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078c2ee51b104ed4ae5d4b7bb5052585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2d27c42ac043129cda4ceebc197a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 4000: {'train': tensor(3.2808), 'val': tensor(3.6570)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da0b8ab5d8a4e3988546ede2ac971d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeadd42151424f1d86e9180aac433b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 5000: {'train': tensor(3.1557), 'val': tensor(3.6049)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acbe3b95dc2421f8f8fb94a4f414439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bba4dd42ab2467e87eb588b975ff14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 6000: {'train': tensor(3.0463), 'val': tensor(3.5842)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d04b578ca954a8d94605d9ceec1cd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f466280b203c44eaa83427171c68f6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 7000: {'train': tensor(2.9420), 'val': tensor(3.5473)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3af20dc3f514e33bd8d8a6d69bd1c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d947c479fb1a4e948c34ba6a4822464b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 8000: {'train': tensor(2.8791), 'val': tensor(3.5328)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af73be86ea924163b6cb26e9446c306b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4114d58dc24a434e92078cf3e0122766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 9000: {'train': tensor(2.7953), 'val': tensor(3.5346)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551ac1eecd474714b7fff1cfbc88d349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951d760f7a624051b91ab19281ad4d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated loss at iteration 10000: {'train': tensor(2.7412), 'val': tensor(3.5207)}\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for iter in tqdm_notebook(range(max_iters)):\n",
    "    with torch.autocast(device, torch.bfloat16):\n",
    "        if iter % eval_interval == 0:\n",
    "            estimated_loss = estimate_loss(model)\n",
    "            print(f\"Estimated loss at iteration {iter}: {estimated_loss}\")\n",
    "            torch.save(  # type: ignore\n",
    "                {\n",
    "                    \"epoch\": iter,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"loss\": estimated_loss,\n",
    "                },\n",
    "                f\"model-{iter}.pt\",\n",
    "            )\n",
    "        x, y = get_batch(\"train\")\n",
    "        _, loss = model.forward(x, y)\n",
    "    # optimizer.zero_grad()\n",
    "    if loss is None:\n",
    "        raise ValueError(\"Expected `loss` to be defined during training, got `None`\")\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad()\n",
    "    # loss.backward() # type: ignore\n",
    "    # optimizer.step()\n",
    "\n",
    "estimated_loss = estimate_loss(model)\n",
    "print(f\"Estimated loss at iteration {max_iters}: {estimated_loss}\")\n",
    "torch.save(  # type: ignore\n",
    "    {\n",
    "        \"epoch\": max_iters,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": estimated_loss,\n",
    "    },\n",
    "    f\"model-{max_iters}.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et’s armor and foolish shields open for a time. Primarily the griless diamond boulevard leaps back to the leg with the wisely fitted face as five times rounded and flung off into the back sharp for fellows.\n",
      "Arctic leather notoriously secretively durable enough to alike that when in case the lensarly swamp rings around it may have personally intricate ability. Wing just as the entire great scenician gems has been forged to points of vanity dressed in the armor and is truly forced to take its beating stone below.\n",
      "CHEST PIECES\n",
      "Our scales are of wielding vambraces inscribed to most of the primary flanges at the beginning of the finials, but, it should be fully emerged as it doesn’t have its purpose for a pulpite instrument I served is a flunt of pattern to create a cheap sight. I’ll reflecate their dump behind these shoulders, so I need to go a sail axe in and back to the inner spaces.\n",
      "DAGGERS\n",
      "The rounded dagger and thrusts are the front plate in their waist for precious knaves and twice, as bloomous rivets were large and mounted, but it’s why the Way is dead, but the area is used in a good confidence.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "model.eval()\n",
    "generated: list[int] = list(map(lambda x: x.item(), model.generate(context, stop_token=list(bpe.special_token_to_index.values())[-1])))  # type: ignore\n",
    "print(bpe.decode(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
